{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_MAP = np.asarray(\n",
    "    [[0, 0, 0, 0], [1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]\n",
    ")\n",
    "def create_datapoints(seq, concentration, read_length):\n",
    "    seq = seq[:-1]\n",
    "    F = int(concentration)\n",
    "    L = int(read_length)\n",
    "\n",
    "    length = len(seq)\n",
    "    seq = seq + 'N' * (50 - length)\n",
    "    seq = seq.upper().replace(\"A\", \"1\").replace(\"C\", \"2\")\n",
    "    seq = seq.replace(\"G\", \"3\").replace(\"T\", \"4\").replace(\"N\", \"0\")\n",
    "\n",
    "    X = np.asarray(list(map(int, list(seq))))\n",
    "    X = IN_MAP[X.astype(\"int8\")]\n",
    "\n",
    "    if F == 0:\n",
    "        F = 20 # use a arbitraty value\n",
    "        Y = 0\n",
    "\n",
    "    return X, F, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(target_protein, data_dir, t_file, c_file, protein_concentration, each_class_train_size):\n",
    "\n",
    "    path = os.path.join(data_dir, f\"protein_{target_protein}\")\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    path += '/'\n",
    "\n",
    "    X_train = [] # seq\n",
    "    Y_train = [] # label, 0 for the background data\n",
    "    F_train = [] # concentration\n",
    "    L_train = [] # read length\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "    F_test = []\n",
    "    L_test = []\n",
    "\n",
    "    protein_dict = {}\n",
    "    protein_idx = 0\n",
    "    step = -1\n",
    "    protein_list = list()\n",
    "    t_i, c_i = 0, 0\n",
    "\n",
    "    with open(t_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if t_i > each_class_train_size * 4.4: \n",
    "                break\n",
    "            if t_i%4 == 1:\n",
    "                data, concentration, l = create_datapoints(line, concentration=protein_concentration, read_length=20)\n",
    "                label = 1\n",
    "                if t_i < each_class_train_size * 4:\n",
    "                    X_train.append(data)\n",
    "                    Y_train.append(label)\n",
    "                    F_train.append(concentration)\n",
    "                    L_train.append(l)\n",
    "                elif t_i < each_class_train_size * 4.4:\n",
    "                    X_test.append(data)\n",
    "                    Y_test.append(label)\n",
    "                    F_test.append(concentration)\n",
    "                    L_test.append(l)\n",
    "            t_i += 1\n",
    "        \n",
    "        h5f = h5py.File(path + 'rbns' + '_' + 'train' + '.h5', 'w')\n",
    "        print('Xtrain', np.asarray(X_train).shape)\n",
    "        h5f.create_dataset('X', data=np.asarray(X_train), maxshape=(None, None, 4))\n",
    "        h5f.create_dataset('Y', data=np.asarray(Y_train), maxshape=(None, ))\n",
    "        h5f.create_dataset('F', data=np.asarray(F_train), maxshape=(None, ))\n",
    "        h5f.create_dataset('L', data=np.asarray(L_train), maxshape=(None, ))\n",
    "        h5f.close()\n",
    "\n",
    "        h5f = h5py.File(path + 'rbns' + '_' + 'test' + '.h5', 'w')\n",
    "        print('Xtest', np.asarray(X_test).shape)\n",
    "        h5f.create_dataset('X', data=np.asarray(X_test), maxshape=(None, None, 4))\n",
    "        h5f.create_dataset('Y', data=np.asarray(Y_test), maxshape=(None, ))\n",
    "        h5f.create_dataset('F', data=np.asarray(F_test), maxshape=(None, ))\n",
    "        h5f.create_dataset('L', data=np.asarray(L_test), maxshape=(None, ))\n",
    "        h5f.close()\n",
    "\n",
    "        X_train = []\n",
    "        Y_train = []\n",
    "        F_train = []\n",
    "        L_train = []\n",
    "        X_test = []\n",
    "        Y_test = []\n",
    "        F_test = []\n",
    "        L_test = []\n",
    "    \n",
    "    with open(c_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if c_i > each_class_train_size * 4.4: \n",
    "                break\n",
    "            if c_i%4 == 1:\n",
    "                data, concentration, l = create_datapoints(line, concentration=0, read_length=20)\n",
    "                label = 0\n",
    "                if c_i < each_class_train_size * 4:\n",
    "                    X_train.append(data)\n",
    "                    Y_train.append(label)\n",
    "                    F_train.append(concentration)\n",
    "                    L_train.append(l)\n",
    "                elif c_i < each_class_train_size * 4.4:\n",
    "                    X_test.append(data)\n",
    "                    Y_test.append(label)\n",
    "                    F_test.append(concentration)\n",
    "                    L_test.append(l)\n",
    "            c_i += 1\n",
    "        \n",
    "        h5f = h5py.File(path + 'rbns' + '_' + 'train' + '.h5', 'a')\n",
    "        # print(np.asarray(X_train).shape)\n",
    "        h5f['X'].resize((h5f['X'].shape[0] + np.asarray(X_train).shape[0]), axis=0)\n",
    "        h5f['X'][-np.asarray(X_train).shape[0]:] = np.asarray(X_train)\n",
    "        h5f['Y'].resize((h5f['Y'].shape[0] + np.asarray(Y_train).shape[0]), axis=0)\n",
    "        h5f['Y'][-np.asarray(Y_train).shape[0]:] = np.asarray(Y_train)\n",
    "        h5f['F'].resize((h5f['F'].shape[0] + np.asarray(F_train).shape[0]), axis=0)\n",
    "        h5f['F'][-np.asarray(F_train).shape[0]:] = np.asarray(F_train)\n",
    "        h5f['L'].resize((h5f['L'].shape[0] + np.asarray(L_train).shape[0]), axis=0)\n",
    "        h5f['L'][-np.asarray(L_train).shape[0]:] = np.asarray(L_train)\n",
    "        h5f.close()\n",
    "\n",
    "        h5f = h5py.File(path + 'rbns' + '_' + 'test' + '.h5', 'a')\n",
    "        h5f['X'].resize((h5f['X'].shape[0] + np.asarray(X_test).shape[0]), axis=0)\n",
    "        h5f['X'][-np.asarray(X_test).shape[0]:] = np.asarray(X_test)\n",
    "        h5f['Y'].resize((h5f['Y'].shape[0] + np.asarray(Y_test).shape[0]), axis=0)\n",
    "        h5f['Y'][-np.asarray(Y_test).shape[0]:] = np.asarray(Y_test)\n",
    "        h5f['F'].resize((h5f['F'].shape[0] + np.asarray(F_test).shape[0]), axis=0)\n",
    "        h5f['F'][-np.asarray(F_test).shape[0]:] = np.asarray(F_test)\n",
    "        h5f['L'].resize((h5f['L'].shape[0] + np.asarray(L_test).shape[0]), axis=0)\n",
    "        h5f['L'][-np.asarray(L_test).shape[0]:] = np.asarray(L_test)\n",
    "        h5f.close()\n",
    "\n",
    "        X_train = []\n",
    "        Y_train = []\n",
    "        F_train = []\n",
    "        L_train = []\n",
    "        X_test = []\n",
    "        Y_test = []\n",
    "        F_test = []\n",
    "        L_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"../rbns_raw_data\"\n",
    "HNRNPA1_DATA_DIR = f\"{data_dir}/HNRNPA1_split_reads/\"\n",
    "RALY_DATA_DIR = f\"{data_dir}/RALY/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain (10000, 50, 4)\n",
      "Xtest (1000, 50, 4)\n"
     ]
    }
   ],
   "source": [
    "generate_dataset('HNRNPA1', f\"../dataset_10k/\", HNRNPA1_DATA_DIR+'HNRNPA1_0nM_5.reads', HNRNPA1_DATA_DIR+'HNRNPA1_0nM_input.reads', 5, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain (500000, 50, 4)\n",
      "Xtest (50000, 50, 4)\n"
     ]
    }
   ],
   "source": [
    "generate_dataset('HNRNPA1', f\"../dataset_500k/\", HNRNPA1_DATA_DIR+'HNRNPA1_0nM_5.reads', HNRNPA1_DATA_DIR+'HNRNPA1_0nM_input.reads', 5, 500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain (10000, 50, 4)\n",
      "Xtest (1000, 50, 4)\n"
     ]
    }
   ],
   "source": [
    "generate_dataset('RALY', f\"../dataset_10k/\", RALY_DATA_DIR+'RALY_80.reads', RALY_DATA_DIR+'RALY_input.reads', 80, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain (500000, 50, 4)\n",
      "Xtest (50000, 50, 4)\n"
     ]
    }
   ],
   "source": [
    "generate_dataset('RALY', f\"../dataset_500k/\", RALY_DATA_DIR+'RALY_80.reads', RALY_DATA_DIR+'RALY_input.reads', 80, 500000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d72ff22b97ef322fff9a99326e8cb5462582062f37eb0306d3432c8b1b511f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
